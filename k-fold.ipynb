{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9485b58-321e-4f5b-876f-211f0bfe51eb",
   "metadata": {},
   "source": [
    "## 5-fold cross valdiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb3076-26b2-4d99-8c19-a300c2fbe015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "from dkt.dataloader import Preprocess\n",
    "from dkt import trainer\n",
    "from dkt.utils import setSeeds\n",
    "\n",
    "from dkt.dataloader import get_loaders\n",
    "from dkt.optimizer import get_optimizer\n",
    "from dkt.scheduler import get_scheduler\n",
    "from dkt.criterion import get_criterion\n",
    "from dkt.metric import get_metric\n",
    "from dkt.model import LSTM, LSTMATTN, Bert, Saint\n",
    "from dkt.trainer import get_lr, train, validate, get_model, process_batch, compute_loss, update_params, save_checkpoint\n",
    "import wandb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31298137-533c-4020-8143-d627f1bc23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(mode='train'):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    \n",
    "    parser.add_argument('--seed', default=42, type=int, help='seed')\n",
    "    \n",
    "    parser.add_argument('--device', default='cpu', type=str, help='cpu or gpu')\n",
    "\n",
    "    parser.add_argument('--data_dir', default='/opt/ml/input/data/train_dataset', type=str, help='data directory')\n",
    "    parser.add_argument('--asset_dir', default='asset/', type=str, help='data directory')\n",
    "    \n",
    "    parser.add_argument('--file_name', default='train_data.csv', type=str, help='train file name')\n",
    "    \n",
    "    parser.add_argument('--model_dir', default='models/', type=str, help='model directory')\n",
    "    parser.add_argument('--model_name', default='model.pt', type=str, help='model file name')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='output/', type=str, help='output directory')\n",
    "    parser.add_argument('--test_file_name', default='test_data.csv', type=str, help='test file name')\n",
    "    \n",
    "    parser.add_argument('--max_seq_len', default=20, type=int, help='max sequence length')\n",
    "    parser.add_argument('--num_workers', default=4, type=int, help='number of workers')\n",
    "\n",
    "    # 모델\n",
    "    parser.add_argument('--hidden_dim', default=64, type=int, help='hidden dimension size')\n",
    "    parser.add_argument('--n_layers', default=2, type=int, help='number of layers')\n",
    "    parser.add_argument('--n_heads', default=2, type=int, help='number of heads')\n",
    "    parser.add_argument('--drop_out', default=0.2, type=float, help='drop out rate')\n",
    "    \n",
    "    # 훈련\n",
    "    parser.add_argument('--n_epochs', default=100, type=int, help='number of epochs')\n",
    "    parser.add_argument('--batch_size', default=64, type=int, help='batch size')\n",
    "    parser.add_argument('--lr', default=0.0001, type=float, help='learning rate')\n",
    "    parser.add_argument('--clip_grad', default=10, type=int, help='clip grad')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='for early stopping')\n",
    "    \n",
    "\n",
    "    parser.add_argument('--log_steps', default=50, type=int, help='print log per n steps')\n",
    "    \n",
    "\n",
    "    ### 중요 ###\n",
    "    parser.add_argument('--model', default='saint', type=str, help='model type')\n",
    "    parser.add_argument('--optimizer', default='adam', type=str, help='optimizer type')\n",
    "    parser.add_argument('--scheduler', default='plateau', type=str, help='scheduler type')\n",
    "    \n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b7625-0105-4b29-97aa-a22d2ab838c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args(mode='train')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args.device = device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687c8cb-3272-46d5-8e21-42a10682e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess(args)\n",
    "# set preprocess.train_data\n",
    "preprocess.load_train_data(args.file_name)\n",
    "\n",
    "# get preprocess.train_data\n",
    "tot_train_data = preprocess.get_train_data()\n",
    "print(len(tot_train_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b3d12-adca-4554-a8d9-cd805bd16b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='CV', config=vars(args), tags=[args.model], name=f'kfold_{args.model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce8f60-4abe-4ae7-baae-80a60ede92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'folds/'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffff6ae-ec50-4316-8232-47b5403690ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args, train_data, valid_data, fold):\n",
    "    train_loader, valid_loader = get_loaders(args, train_data, valid_data)\n",
    "    \n",
    "    # only when using warmup scheduler\n",
    "    args.total_steps = int(len(train_loader.dataset) / args.batch_size) * (args.n_epochs)\n",
    "    args.warmup_steps = args.total_steps // 10\n",
    "            \n",
    "    model = get_model(args)\n",
    "    optimizer = get_optimizer(model, args)\n",
    "    scheduler = get_scheduler(optimizer, args)\n",
    "\n",
    "    best_auc = -1\n",
    "    best_acc = -1  # best_auc에 따라서 결정됨\n",
    "    early_stopping_counter = 0\n",
    "    best_auc_epoch = 0\n",
    "    print(f\"########## Fold {fold} ##########\")\n",
    "    for epoch in range(args.n_epochs):\n",
    "\n",
    "        print(f\"Start Training: Epoch {epoch + 1}\")\n",
    "        start = time.time()\n",
    "        ### TRAIN\n",
    "        train_auc, train_acc, train_loss = train(train_loader, model, optimizer, args)\n",
    "        \n",
    "        ### VALID\n",
    "        auc, acc,_ , _ = validate(valid_loader, model, args)\n",
    "\n",
    "        sec = time.time() - start\n",
    "        times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "        times = times[0]\n",
    "        print(f'<<<<<<<<<<  {epoch + 1} EPOCH spent : {times}  >>>>>>>>>>')\n",
    "\n",
    "        ### TODO: model save or early stopping\n",
    "        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"train_auc\": train_auc, \"train_acc\":train_acc,\n",
    "                  \"valid_auc\":auc, \"valid_acc\":acc, \"Learning_rate\": get_lr(optimizer),})\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_acc = acc\n",
    "            best_auc_epoch = epoch+1\n",
    "            # torch.nn.DataParallel로 감싸진 경우 원래의 model을 가져옵니다.\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model_to_save.state_dict(),\n",
    "                },\n",
    "                MODEL_DIR, f'model_fold_{fold}.pt',\n",
    "            )\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= args.patience:\n",
    "                print(f'EarlyStopping counter: {early_stopping_counter} out of {args.patience}')\n",
    "                print(f'Best AUC epoch: {best_auc_epoch}')\n",
    "                break\n",
    "\n",
    "        # scheduler\n",
    "        if args.scheduler == 'plateau':\n",
    "            scheduler.step(best_auc)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            \n",
    "    # model 메모리 지우기        \n",
    "    model.cpu()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return best_acc, best_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93989c-cdec-4527-a927-f3531779060f",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32baf3-11cd-43bb-adb6-56cc8024e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162003a-3b87-4534-a718-f2ccdcf74e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋의 index를 반환한다\n",
    "fold = 1\n",
    "acc_list = []\n",
    "auc_list = []\n",
    "for train_index, valid_index in kf.split(tot_train_data):\n",
    "    train_data, valid_data = tot_train_data[train_index], tot_train_data[valid_index]\n",
    "    acc, auc = run(args, train_data, valid_data, fold)\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "    print('')\n",
    "    print(f'Fold {fold} ACC: {acc}')\n",
    "    print(f'Fold {fold} AUC: {auc}')\n",
    "    print('')\n",
    "    fold+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e454ef-6acf-484f-b5fd-e0c889fe4bb8",
   "metadata": {},
   "source": [
    "## k-fold 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e92f94-2b0d-4743-9a65-7e46dc8cce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc 평균\n",
    "print(f'acc = {acc_list}')\n",
    "print(f'auc = {auc_list}')\n",
    "acc_mean = sum(acc_list)/len(acc_list)\n",
    "auc_mean = sum(auc_list)/len(auc_list)\n",
    "print(f'acc_mean: {acc_mean}')\n",
    "print(f'auc_mean: {auc_mean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a559c-f7dc-499e-87c9-10d8e67217aa",
   "metadata": {},
   "source": [
    "## Inferecne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc660fc-a81f-43c3-b711-e19259c16293",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.load_test_data(args.test_file_name)\n",
    "test_data = preprocess.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417644c4-e6a9-43d6-91e3-1b2966ac469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_n = 5\n",
    "FOLD_OUTPUT_DIR = 'fold_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795fea3-a27a-488b-a720-558f42b7eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args, fold):\n",
    "    \n",
    "    model_path = os.path.join(MODEL_DIR, f'model_fold_{fold}.pt')\n",
    "    print(\"Loading Model from:\", model_path)\n",
    "    load_state = torch.load(model_path)\n",
    "    model = get_model(args)\n",
    "\n",
    "    # 1. load model state\n",
    "    model.load_state_dict(load_state['state_dict'], strict=True)\n",
    "   \n",
    "    \n",
    "    print(\"Loading Model from:\", model_path, \"...Finished.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e452ce-d82c-4355-9dd7-1a0db87ba5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(args, test_data, fold):\n",
    "    \n",
    "    model = load_model(args, fold)\n",
    "    model.eval()\n",
    "    _, test_loader = get_loaders(args, None, test_data)\n",
    "    \n",
    "    \n",
    "    total_preds = []\n",
    "    \n",
    "    for step, batch in enumerate(test_loader):\n",
    "        input = process_batch(batch, args)\n",
    "\n",
    "        preds = model(input)\n",
    "        \n",
    "\n",
    "        # predictions\n",
    "        preds = preds[:,-1]\n",
    "        \n",
    "\n",
    "        if args.device == 'cuda':\n",
    "            preds = preds.to('cpu').detach().numpy()\n",
    "        else: # cpu\n",
    "            preds = preds.detach().numpy()\n",
    "            \n",
    "        total_preds+=list(preds)\n",
    "\n",
    "    write_path = os.path.join(FOLD_OUTPUT_DIR, f\"output_fold_{fold}.csv\")\n",
    "    if not os.path.exists(FOLD_OUTPUT_DIR):\n",
    "        os.makedirs(FOLD_OUTPUT_DIR)    \n",
    "    with open(write_path, 'w', encoding='utf8') as w:\n",
    "        print(\"writing prediction : {}\".format(write_path))\n",
    "        w.write(\"id,prediction\\n\")\n",
    "        for id, p in enumerate(total_preds):\n",
    "            w.write('{},{}\\n'.format(id,p))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85e148-68da-4aa2-8f1f-7f6ffd97f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, fold_n+1):\n",
    "    inference(args, test_data, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb843e-7cf4-409c-bfae-cfc4b8e322a9",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc58e14-3744-441b-ba72-3ba23c001da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1 = pd.read_csv('./fold_output/output_fold_1.csv').prediction\n",
    "fold_2 = pd.read_csv('./fold_output/output_fold_2.csv').prediction\n",
    "fold_3 = pd.read_csv('./fold_output/output_fold_3.csv').prediction\n",
    "fold_4 = pd.read_csv('./fold_output/output_fold_4.csv').prediction\n",
    "fold_5 = pd.read_csv('./fold_output/output_fold_5.csv').prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e8ef7-fe5c-46ea-a32c-e090acea45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([fold_1, fold_2, fold_3, fold_4, fold_5], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5083b1e-fb62-400d-ae47-b2e5eeb94273",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = concat_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b56bd8-34c4-41fe-857a-062bcd02cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = os.path.join(FOLD_OUTPUT_DIR, \"ensemble_output.csv\")\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(mean_df):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
